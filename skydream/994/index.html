<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>PySpark|DataFrame操作指南 | sky_dream</title><meta name="keywords" content="pyspark,DataFrame"><meta name="author" content="sky_dream"><meta name="copyright" content="sky_dream"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="最近有用到PySpark及一些DataFrame之类的操作，简单做个整理。  查  行元素查询操作 像SQL那样打印列表前20元素 show函数内可用int类型指定要打印的行数： 12df.show()df.show(30) 查询概况,获取指定字段的统计信息describe(cols: String*) 这个方法可以动态的传入一个或多个String类型的字段名，结果仍然为DataFrame对象，用"><meta property="og:type" content="article"><meta property="og:title" content="PySpark|DataFrame操作指南"><meta property="og:url" content="https://blog.skysmile.ltd/skydream/994/index.html"><meta property="og:site_name" content="sky_dream"><meta property="og:description" content="最近有用到PySpark及一些DataFrame之类的操作，简单做个整理。  查  行元素查询操作 像SQL那样打印列表前20元素 show函数内可用int类型指定要打印的行数： 12df.show()df.show(30) 查询概况,获取指定字段的统计信息describe(cols: String*) 这个方法可以动态的传入一个或多个String类型的字段名，结果仍然为DataFrame对象，用"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.skysmile.ltd/skydream/994//pyspark01.jpg"><meta property="article:published_time" content="2019-11-05T11:54:03.000Z"><meta property="article:modified_time" content="2022-05-05T11:25:03.552Z"><meta property="article:author" content="sky_dream"><meta property="article:tag" content="PySpark"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.skysmile.ltd/skydream/994//pyspark01.jpg"><link rel="shortcut icon" href="/img/avatar009.webp"><link rel="canonical" href="https://blog.skysmile.ltd/skydream/994/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ma+Shan+Zheng&amp;display=swap" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},noticeOutdate:{limitDay:100,position:"top",messagePrev:"文章最后编辑在",messageNext:"天以前, 文章的内容可能已经过时。"},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-left"},source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css"}},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"PySpark|DataFrame操作指南",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-05-05 19:25:03"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/font-awesome-animation.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="/css/mycss.css" media="defer" onload='this.media="all"'><svg aria-hidden="true" style="position:absolute;overflow:hidden;width:0;height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248 626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="sky_dream" type="application/atom+xml"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar009.jpg" onerror='onerror=null,src="img/friend_404.gif"' alt="avatar"></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home faa-pulse"></i> <span>主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book faa-pulse"></i> <span>文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive faa-pulse"></i> <span>归档</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open faa-pulse"></i> <span>分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags faa-pulse"></i> <span>标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-gamepad faa-pulse"></i> <span>娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images faa-pulse"></i> <span>相册</span></a></li><li><a class="site-page child" href="/Comics/"><i class="fa-fw fas fa-tv faa-pulse"></i> <span>番剧</span></a></li><li><a class="site-page child" href="/Games/"><i class="fa-fw fab fa-steam faa-pulse"></i> <span>Steam</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link faa-pulse"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heartbeat faa-tada animated"></i> <span>(*^_^*)</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/skydream/994/%5Cpyspark01.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">sky_dream</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home faa-pulse"></i> <span>主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book faa-pulse"></i> <span>文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive faa-pulse"></i> <span>归档</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open faa-pulse"></i> <span>分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags faa-pulse"></i> <span>标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-gamepad faa-pulse"></i> <span>娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images faa-pulse"></i> <span>相册</span></a></li><li><a class="site-page child" href="/Comics/"><i class="fa-fw fas fa-tv faa-pulse"></i> <span>番剧</span></a></li><li><a class="site-page child" href="/Games/"><i class="fa-fw fab fa-steam faa-pulse"></i> <span>Steam</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link faa-pulse"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heartbeat faa-tada animated"></i> <span>(*^_^*)</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PySpark|DataFrame操作指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-11-05T11:54:03.000Z" title="发表于 2019-11-05 19:54:03">2019-11-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-05T11:25:03.552Z" title="更新于 2022-05-05 19:25:03">2022-05-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Spark/">Spark</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>最近有用到PySpark及一些DataFrame之类的操作，简单做个整理。</p><h1 id="查"><a class="markdownIt-Anchor" href="#查"></a> 查</h1><h2 id="行元素查询操作"><a class="markdownIt-Anchor" href="#行元素查询操作"></a> 行元素查询操作</h2><p>像SQL那样打印列表前20元素<br>show函数内可用int类型指定要打印的行数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line">df.show(<span class="number">30</span>)</span><br></pre></td></tr></table></figure><p>查询概况,获取指定字段的统计信息<code>describe(cols: String*)</code></p><p>这个方法可以动态的传入一个或多个String类型的字段名，结果仍然为DataFrame对象，用于统计数值类型字段的统计值，比如count, mean, stddev, min, max等。<br>使用方法如下，其中c1字段为字符类型，c2字段为整型，c4字段为浮点型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF .describe(<span class="string">&quot;c1&quot;</span> , <span class="string">&quot;c2&quot;</span>, <span class="string">&quot;c4&quot;</span> ).show()</span><br></pre></td></tr></table></figure><p>以及查询类型，之前是<code>type</code>，现在是<code>df.printSchema()</code>以树的形式打印概要。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- user_pin: string (nullable = true)</span><br><span class="line"> |-- a: string (nullable = true)</span><br><span class="line"> |-- b: string (nullable = true)</span><br><span class="line"> |-- c: string (nullable = true)</span><br><span class="line"> |-- d: string (nullable = true)</span><br><span class="line"> |-- e: string (nullable = true)</span><br></pre></td></tr></table></figure><p>如上图所示，只是打印出来。</p><p><code>first, head, take, takeAsList：</code>获取若干行记录<br>这里列出的四个方法比较类似，其中</p><ul><li><code>first</code>获取第一行记录</li><li><code>head</code>获取第一行记录，<code>head(n: Int)</code>获取前n行记录</li><li><code>take(n: Int)</code>获取前n行数据</li><li><code>takeAsList(n: Int)</code>获取前n行数据，并以<code>List</code>的形式展现，以Row或者Array[Row]的形式返回一行或多行数据。</li></ul><p><code>first</code>和<code>head</code>功能相同。</p><p><code>take</code>和<code>takeAsList</code>方法会将获得到的数据返回到<code>Driver</code>端，所以，使用这两个方法时需要注意数据量，以免<code>Driver</code>发生<code>OutOfMemoryError</code></p><p>获取头几行到本地：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ist = df.head(<span class="number">3</span>)   <span class="comment"># Example: [Row(a=1, b=1), Row(a=2, b=2), ... ...]</span></span><br><span class="line"><span class="built_in">list</span> = df.take(<span class="number">5</span>)   <span class="comment"># Example: [Row(a=1, b=1), Row(a=2, b=2), ... ...]</span></span><br></pre></td></tr></table></figure><p>查询总行数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int_num = df.count()</span><br></pre></td></tr></table></figure><p>取别名</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.select(df.age.alias(<span class="string">&#x27;age_value&#x27;</span>),<span class="string">&#x27;name&#x27;</span>)</span><br></pre></td></tr></table></figure><p>查询某列为null的行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> isnull</span><br><span class="line">df = df.<span class="built_in">filter</span>(isnull(<span class="string">&quot;col_a&quot;</span>))</span><br></pre></td></tr></table></figure><p>输出<code>list</code>类型，<code>list</code>中每个元素是Row类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span> = df.collect()</span><br></pre></td></tr></table></figure><p>注：此方法将所有数据全部导入到本地，返回一个Array对象</p><p>去重set操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.select(<span class="string">&#x27;columns&#x27;</span>).distinct().show()</span><br></pre></td></tr></table></figure><p>跟<code>py</code>中的set一样，可以<code>distinct()</code>一下去重，同时也可以<code>.count()</code>计算剩余个数</p><p>随机抽样<br>随机抽样有两种方式，一种是在HIVE里面查数随机；另一种是在<code>pyspark</code>之中。</p><p><code>HIVE</code>里面查数随机</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sql</span> <span class="operator">=</span> &quot;select * from data order by rand()  limit 2000&quot;</span><br></pre></td></tr></table></figure><p><code>pyspark</code>之中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample = result.sample(<span class="literal">False</span>,<span class="number">0.5</span>,<span class="number">0</span>) <span class="comment"># randomly select 50% of lines</span></span><br></pre></td></tr></table></figure><h2 id="列元素操作"><a class="markdownIt-Anchor" href="#列元素操作"></a> 列元素操作</h2><p>获取Row元素的所有列名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = Row(age=<span class="number">11</span>, name=<span class="string">&#x27;Alice&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> r.columns    <span class="comment">#  [&#x27;age&#x27;, &#x27;name&#x27;]</span></span><br></pre></td></tr></table></figure><p>选择一列或多列：<code>select</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&quot;age&quot;</span>]</span><br><span class="line">df.age</span><br><span class="line">df.select(“name”)</span><br><span class="line">df.select(df[‘name’], df[‘age’]+<span class="number">1</span>)</span><br><span class="line">df.select(df.a, df.b, df.c)    <span class="comment"># 选择a、b、c三列</span></span><br><span class="line">df.select(df[<span class="string">&quot;a&quot;</span>], df[<span class="string">&quot;b&quot;</span>], df[<span class="string">&quot;c&quot;</span>])    <span class="comment"># 选择a、b、c三列</span></span><br></pre></td></tr></table></figure><p>重载的<code>select</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.select(jdbcDF( <span class="string">&quot;id&quot;</span> ), jdbcDF( <span class="string">&quot;id&quot;</span>) + <span class="number">1</span> ).show( false)</span><br></pre></td></tr></table></figure><p>会同时显示<code>id列 + id + 1列</code></p><p>还可以用<code>where</code>按条件选择</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF .where(<span class="string">&quot;id = 1 or c1 = &#x27;b&#x27;&quot;</span> ).show()</span><br></pre></td></tr></table></figure><h2 id="排序"><a class="markdownIt-Anchor" href="#排序"></a> 排序</h2><p><code>orderBy</code>和<code>sort</code>：按指定字段排序，默认为升序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.orderBy(train.Purchase.desc()).show(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|</span><br><span class="line">+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">|1003160| P00052842|     M|26-35|        17|            C|                         3|             0|                10|                15|              null|   23961|</span><br><span class="line">|1002272| P00052842|     M|26-35|         0|            C|                         1|             0|                10|                15|              null|   23961|</span><br><span class="line">|1001474| P00052842|     M|26-35|         4|            A|                         2|             1|                10|                15|              null|   23961|</span><br><span class="line">|1005848| P00119342|     M|51-55|        20|            A|                         0|             1|                10|                13|              null|   23960|</span><br><span class="line">|1005596| P00117642|     M|36-45|        12|            B|                         1|             0|                10|                16|              null|   23960|</span><br><span class="line">+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure><p>按指定字段排序。加个<code>-</code>表示降序排序</p><h2 id="抽样"><a class="markdownIt-Anchor" href="#抽样"></a> 抽样</h2><p><code>sample</code>是抽样函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1 = train.sample(<span class="literal">False</span>, <span class="number">0.2</span>, <span class="number">42</span>)</span><br><span class="line">t2 = train.sample(<span class="literal">False</span>, <span class="number">0.2</span>, <span class="number">43</span>)</span><br><span class="line">t1.count(),t2.count()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">(109812, 109745)</span><br></pre></td></tr></table></figure><p><code>withReplacement = True or False</code>代表是否有放回。<br><code>fraction = x, where x = .5，</code>代表抽取百分比</p><h2 id="按条件筛选when-between"><a class="markdownIt-Anchor" href="#按条件筛选when-between"></a> 按条件筛选when / between</h2><p><code>when(condition, value1).otherwise(value2)</code>联合使用：<br>那么：当满足条件<code>condition</code>的指赋值为<code>values1</code>,不满足条件的则赋值为<code>values2</code>.<br><code>otherwise</code>表示，不满足条件的情况下，应该赋值为啥。</p><p><code>demo1</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line">df.select(df.name, F.when(df.age &gt; <span class="number">4</span>, <span class="number">1</span>).when(df.age &lt; <span class="number">3</span>, -<span class="number">1</span>).otherwise(<span class="number">0</span>)).show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+-----+------------------------------------------------------------+</span><br><span class="line">| name|CASE WHEN (age &gt; 4) THEN 1 WHEN (age &lt; 3) THEN -1 ELSE 0 END|</span><br><span class="line">+-----+------------------------------------------------------------+</span><br><span class="line">|Alice|                                                          -1|</span><br><span class="line">|  Bob|                                                           1|</span><br><span class="line">+-----+------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p><code>demo 2:多个when串联</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(<span class="string">&#x27;mod_val_test1&#x27;</span>,F.when(df[<span class="string">&#x27;rand&#x27;</span>] &lt;= <span class="number">0.35</span>,<span class="number">1</span>).when(df[<span class="string">&#x27;rand&#x27;</span>] &lt;= <span class="number">0.7</span>, <span class="number">2</span>).otherwise(<span class="number">3</span>))</span><br><span class="line">between(lowerBound, upperBound)</span><br><span class="line">筛选出某个范围内的值，返回的是TRUE <span class="keyword">or</span> FALSE</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.select(df.name, df.age.between(<span class="number">2</span>, <span class="number">4</span>)).show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+-----+---------------------------+</span><br><span class="line">| name|((age &gt;= 2) AND (age &lt;= 4))|</span><br><span class="line">+-----+---------------------------+</span><br><span class="line">|Alice|                       true|</span><br><span class="line">|  Bob|                      false|</span><br><span class="line">+-----+---------------------------+</span><br></pre></td></tr></table></figure><h1 id="增-改"><a class="markdownIt-Anchor" href="#增-改"></a> 增、改</h1><h2 id="新建数据"><a class="markdownIt-Anchor" href="#新建数据"></a> 新建数据</h2><p>有这么两种常规的新建数据方式：<code>createDataFrame</code>、<code>.toDF()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.createDataFrame(pd.dataframe())</span><br></pre></td></tr></table></figure><p>是把<code>pandas</code>的<code>dataframe</code>转化为<code>spark.dataframe</code>格式，所以可以作为两者的格式转化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line">row = Row(<span class="string">&quot;spe_id&quot;</span>, <span class="string">&quot;InOther&quot;</span>)</span><br><span class="line">x = [<span class="string">&#x27;x1&#x27;</span>,<span class="string">&#x27;x2&#x27;</span>]</span><br><span class="line">y = [<span class="string">&#x27;y1&#x27;</span>,<span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line">new_df = sc.parallelize([row(x[i], y[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]).toDF()</span><br></pre></td></tr></table></figure><p><code>Row</code>代表的是该数据集的列名。</p><h2 id="新增数据列-withcolumn"><a class="markdownIt-Anchor" href="#新增数据列-withcolumn"></a> 新增数据列 withColumn</h2><p><code>withColumn</code>是通过添加或替换与现有列有相同的名字的列，返回一个新的<code>DataFrame</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result3.withColumn(<span class="string">&#x27;label&#x27;</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>或者案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.withColumn(<span class="string">&#x27;Purchase_new&#x27;</span>,train.Purchase/<span class="number">2.0</span>).select(<span class="string">&#x27;Purchase&#x27;</span>,<span class="string">&#x27;Purchase_new&#x27;</span>).show(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+--------+------------+</span><br><span class="line">|Purchase|Purchase_new|</span><br><span class="line">+--------+------------+</span><br><span class="line">|    8370|      4185.0|</span><br><span class="line">|   15200|      7600.0|</span><br><span class="line">|    1422|       711.0|</span><br><span class="line">|    1057|       528.5|</span><br><span class="line">|    7969|      3984.5|</span><br><span class="line">+--------+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure><p><strong>报错：</strong><code>AssertionError: col should be Column</code>，一定要指定某现有列</p><p>有两种方式可以实现：</p><p>一种方式通过<code>functions</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions</span><br><span class="line">result3 = result3.withColumn(<span class="string">&#x27;label&#x27;</span>,  functions.lit(<span class="number">0</span>))</span><br></pre></td></tr></table></figure><p>但是如何新增一个特别<code>List</code><br><code>python</code>中的<code>list</code>不能直接添加到<code>dataframe</code>中，需要先将<code>list</code>转为新的<code>dataframe</code>,然后新的<code>dataframe</code>和老的<code>dataframe</code>进行<code>join</code>操作, 下面的例子会先新建一个<code>dataframe</code>，然后将<code>list</code>转为<code>dataframe</code>，然后将两者<code>join</code>起来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> lit</span><br><span class="line"></span><br><span class="line">df = sqlContext.createDataFrame(</span><br><span class="line">    [(<span class="number">1</span>, <span class="string">&quot;a&quot;</span>, <span class="number">23.0</span>), (<span class="number">3</span>, <span class="string">&quot;B&quot;</span>, -<span class="number">23.0</span>)], (<span class="string">&quot;x1&quot;</span>, <span class="string">&quot;x2&quot;</span>, <span class="string">&quot;x3&quot;</span>))</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> monotonically_increasing_id</span><br><span class="line">df = df.withColumn(<span class="string">&quot;id&quot;</span>, monotonically_increasing_id())</span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+---+-----+---+</span><br><span class="line">| x1| x2|   x3| id|</span><br><span class="line">+---+---+-----+---+</span><br><span class="line">|  1|  a| 23.0|  0|</span><br><span class="line">|  3|  B|-23.0|  1|</span><br><span class="line">+---+---+-----+---+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line">l = [<span class="string">&#x27;jerry&#x27;</span>, <span class="string">&#x27;tom&#x27;</span>]</span><br><span class="line">row = Row(<span class="string">&quot;pid&quot;</span>, <span class="string">&quot;name&quot;</span>)</span><br><span class="line">new_df = sc.parallelize([row(i, l[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(l))]).toDF()</span><br><span class="line">new_df.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+-----+</span><br><span class="line">|pid| name|</span><br><span class="line">+---+-----+</span><br><span class="line">|  0|jerry|</span><br><span class="line">|  1|  tom|</span><br><span class="line">+---+-----+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">join_df = df.join(new_df, df.<span class="built_in">id</span>==new_df.pid)</span><br><span class="line">join_df.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+---+-----+---+---+-----+</span><br><span class="line">| x1| x2|   x3| id|pid| name|</span><br><span class="line">+---+---+-----+---+---+-----+</span><br><span class="line">|  1|  a| 23.0|  0|  0|jerry|</span><br><span class="line">|  3|  B|-23.0|  1|  1|  tom|</span><br><span class="line">+---+---+-----+---+---+-----+</span><br></pre></td></tr></table></figure><p>**注意！！！**其中，<code>monotonically_increasing_id()</code>生成的ID保证是单调递增和唯一的，但不是连续的。<br>所以，有可能，单调到1-140000，到了第144848个，就变成一长串：8845648744563，所以千万要注意！！</p><p>另一种方式通过另一个已有变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result3 = result3.withColumn(<span class="string">&#x27;label&#x27;</span>,  df.result*<span class="number">0</span> )</span><br></pre></td></tr></table></figure><p>修改原有<code>df[“xx”]</code>列的所有值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(“xx”, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>修改列的类型（类型投射）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(<span class="string">&quot;year2&quot;</span>, df[<span class="string">&quot;year1&quot;</span>].cast(<span class="string">&quot;Int&quot;</span>))</span><br></pre></td></tr></table></figure><p>修改列名:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.withColumnRenamed( <span class="string">&quot;id&quot;</span> , <span class="string">&quot;idx&quot;</span> )</span><br></pre></td></tr></table></figure><h2 id="过滤数据"><a class="markdownIt-Anchor" href="#过滤数据"></a> 过滤数据</h2><p>过滤数据（<code>filter</code>和<code>where</code>方法相同）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = df.<span class="built_in">filter</span>(df[<span class="string">&#x27;age&#x27;</span>]&gt;<span class="number">21</span>)</span><br><span class="line">df = df.where(df[<span class="string">&#x27;age&#x27;</span>]&gt;<span class="number">21</span>)</span><br><span class="line"><span class="comment">#多个条件</span></span><br><span class="line">jdbcDF .<span class="built_in">filter</span>(“<span class="built_in">id</span> = <span class="number">1</span> <span class="keyword">or</span> c1 = ‘b’” ).show()</span><br></pre></td></tr></table></figure><p>对<code>null</code>或<code>nan</code>数据进行过滤：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> isnan, isnull</span><br><span class="line">df = df.<span class="built_in">filter</span>(isnull(<span class="string">&quot;a&quot;</span>))  <span class="comment"># 把a列里面数据为null的筛选出来（代表python的None类型）</span></span><br><span class="line">df = df.<span class="built_in">filter</span>(isnan(<span class="string">&quot;a&quot;</span>))  <span class="comment"># 把a列里面数据为nan的筛选出来（Not a Number，非数字数据）</span></span><br></pre></td></tr></table></figure><h1 id="合并-join-union"><a class="markdownIt-Anchor" href="#合并-join-union"></a> 合并 join / union</h1><h2 id="横向拼接"><a class="markdownIt-Anchor" href="#横向拼接"></a> 横向拼接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result3 = result1.union(result2)</span><br><span class="line">jdbcDF.unionALL(jdbcDF.limit(<span class="number">1</span>)) <span class="comment"># unionALL</span></span><br></pre></td></tr></table></figure><h2 id="join根据条件"><a class="markdownIt-Anchor" href="#join根据条件"></a> Join根据条件</h2><p><strong>单字段Join</strong><br>合并2个表的<code>join</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_join = df_left.join(df_right, df_left.key == df_right.key, <span class="string">&quot;inner&quot;</span>)</span><br></pre></td></tr></table></figure><p>其中，方法可以为：<code>inner, outer, left_outer, right_outer, leftsemi.</code><br>其中注意，一般需要改为：<code>left_outer</code></p><p><strong>多字段join</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">joinDF1.join(joinDF2, Seq(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>)）</span><br></pre></td></tr></table></figure><p><strong>混合字段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">joinDF1.join(joinDF2 , joinDF1(<span class="string">&quot;id&quot;</span> ) === joinDF2( <span class="string">&quot;t1_id&quot;</span>))</span><br></pre></td></tr></table></figure><p>跟pandas 里面的<code>left_on,right_on</code></p><h2 id="求并集-交集"><a class="markdownIt-Anchor" href="#求并集-交集"></a> 求并集、交集</h2><p>来看一个例子，先构造两个<code>dataframe</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sentenceDataFrame = spark.createDataFrame((</span><br><span class="line">      (<span class="number">1</span>, <span class="string">&quot;asf&quot;</span>),</span><br><span class="line">      (<span class="number">2</span>, <span class="string">&quot;2143&quot;</span>),</span><br><span class="line">      (<span class="number">3</span>, <span class="string">&quot;rfds&quot;</span>)</span><br><span class="line">    )).toDF(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">sentenceDataFrame.show()</span><br><span class="line"></span><br><span class="line">sentenceDataFrame1 = spark.createDataFrame((</span><br><span class="line">      (<span class="number">1</span>, <span class="string">&quot;asf&quot;</span>),</span><br><span class="line">      (<span class="number">2</span>, <span class="string">&quot;2143&quot;</span>),</span><br><span class="line">      (<span class="number">4</span>, <span class="string">&quot;f8934y&quot;</span>)</span><br><span class="line">    )).toDF(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;sentence&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="差集"><a class="markdownIt-Anchor" href="#差集"></a> 差集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">newDF = sentenceDataFrame1.select(<span class="string">&quot;sentence&quot;</span>).subtract(sentenceDataFrame.select(<span class="string">&quot;sentence&quot;</span>))</span><br><span class="line">newDF.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+--------+</span><br><span class="line">|sentence|</span><br><span class="line">+--------+</span><br><span class="line">|  f8934y|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure><h2 id="交集"><a class="markdownIt-Anchor" href="#交集"></a> 交集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">newDF = sentenceDataFrame1.select(<span class="string">&quot;sentence&quot;</span>).intersect(sentenceDataFrame.select(<span class="string">&quot;sentence&quot;</span>))</span><br><span class="line">newDF.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+--------+</span><br><span class="line">|sentence|</span><br><span class="line">+--------+</span><br><span class="line">|     asf|</span><br><span class="line">|    2143|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure><h2 id="并集"><a class="markdownIt-Anchor" href="#并集"></a> 并集</h2><h3 id="union"><a class="markdownIt-Anchor" href="#union"></a> union</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">newDF = sentenceDataFrame1.select(<span class="string">&quot;sentence&quot;</span>).union(sentenceDataFrame.select(<span class="string">&quot;sentence&quot;</span>))</span><br><span class="line">newDF.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------+</span><br><span class="line">|sentence|</span><br><span class="line">+--------+</span><br><span class="line">|     asf|</span><br><span class="line">|    2143|</span><br><span class="line">|  f8934y|</span><br><span class="line">|     asf|</span><br><span class="line">|    2143|</span><br><span class="line">|    rfds|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure><h3 id="unionall"><a class="markdownIt-Anchor" href="#unionall"></a> unionAll</h3><p><code>unionAll</code>方法：对两个DataFrame进行组合,类似于<code>SQL</code>中的<code>UNION ALL</code>操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.unionALL(jdbcDF.limit(<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h2 id="并集-去重"><a class="markdownIt-Anchor" href="#并集-去重"></a> 并集 + 去重</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">newDF = sentenceDataFrame1.select(<span class="string">&quot;sentence&quot;</span>).union(sentenceDataFrame.select(<span class="string">&quot;sentence&quot;</span>)).distinct()</span><br><span class="line">newDF.show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+--------+</span><br><span class="line">|sentence|</span><br><span class="line">+--------+</span><br><span class="line">|    rfds|</span><br><span class="line">|     asf|</span><br><span class="line">|    2143|</span><br><span class="line">|  f8934y|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure><h2 id="分割行转列"><a class="markdownIt-Anchor" href="#分割行转列"></a> 分割：行转列</h2><p>有时候需要根据某个字段内容进行分割，然后生成多行，这时可以使用<code>explode</code>方法<br>下面代码中，根据<code>c3</code>字段中的空格将字段内容进行分割，分割的内容存储在新的字段<code>c3_</code>中，如下所示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.explode( <span class="string">&quot;c3&quot;</span> , <span class="string">&quot;c3_&quot;</span> )&#123;time: String =&gt; time.split( <span class="string">&quot; &quot;</span> )&#125;</span><br></pre></td></tr></table></figure><h1 id="统计"><a class="markdownIt-Anchor" href="#统计"></a> 统计</h1><h2 id="频数统计与筛选"><a class="markdownIt-Anchor" href="#频数统计与筛选"></a> 频数统计与筛选</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.stat.freqItems(Seq (<span class="string">&quot;c1&quot;</span>) , <span class="number">0.3</span>).show()</span><br></pre></td></tr></table></figure><p>根据<code>c4</code>字段，统计该字段值出现频率在30%以上的内容</p><h2 id="分组统计"><a class="markdownIt-Anchor" href="#分组统计"></a> 分组统计</h2><p><strong>交叉分析</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.crosstab(<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Gender&#x27;</span>).show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+----------+-----+------+</span><br><span class="line">|Age_Gender|    F|     M|</span><br><span class="line">+----------+-----+------+</span><br><span class="line">|      0-17| 5083| 10019|</span><br><span class="line">|     46-50|13199| 32502|</span><br><span class="line">|     18-25|24628| 75032|</span><br><span class="line">|     36-45|27170| 82843|</span><br><span class="line">|       55+| 5083| 16421|</span><br><span class="line">|     51-55| 9894| 28607|</span><br><span class="line">|     26-35|50752|168835|</span><br><span class="line">+----------+-----+------+</span><br></pre></td></tr></table></figure><p><strong>groupBy方法整合：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.groupby(<span class="string">&#x27;Age&#x27;</span>).agg(&#123;<span class="string">&#x27;Purchase&#x27;</span>: <span class="string">&#x27;mean&#x27;</span>&#125;).show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+-----+-----------------+</span><br><span class="line">|  Age|    avg(Purchase)|</span><br><span class="line">+-----+-----------------+</span><br><span class="line">|51-55|9534.808030960236|</span><br><span class="line">|46-50|9208.625697468327|</span><br><span class="line">| 0-17|8933.464640444974|</span><br><span class="line">|36-45|9331.350694917874|</span><br><span class="line">|26-35|9252.690632869888|</span><br><span class="line">|  55+|9336.280459449405|</span><br><span class="line">|18-25|9169.663606261289|</span><br><span class="line">+-----+-----------------+</span><br></pre></td></tr></table></figure><p><strong>另外一些demo：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;x1&#x27;</span>].groupby(df[<span class="string">&#x27;x2&#x27;</span>]).count().reset_index(name=<span class="string">&#x27;x1&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>分组汇总</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.groupby(<span class="string">&#x27;Age&#x27;</span>).count().show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+-----+------+</span><br><span class="line">|  Age| count|</span><br><span class="line">+-----+------+</span><br><span class="line">|51-55| 38501|</span><br><span class="line">|46-50| 45701|</span><br><span class="line">| 0-17| 15102|</span><br><span class="line">|36-45|110013|</span><br><span class="line">|26-35|219587|</span><br><span class="line">|  55+| 21504|</span><br><span class="line">|18-25| 99660|</span><br><span class="line">+-----+------+</span><br></pre></td></tr></table></figure><p><strong>应用多个函数：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions</span><br><span class="line">df.groupBy(“A”).agg(functions.avg(“B”), functions.<span class="built_in">min</span>(“B”), functions.<span class="built_in">max</span>(“B”)).show()</span><br></pre></td></tr></table></figure><p>整合后<code>GroupedData</code>类型可用的方法（均返回<code>DataFrame</code>类型）：<br><strong>avg(cols)</strong> —— 计算每组中一列或多列的平均值<br><strong>count()</strong> —— 计算每组中一共有多少行，返回<code>DataFrame</code>有2列，一列为分组的组名，另一列为行总数<br><strong>max(cols)</strong> —— 计算每组中一列或多列的最大值<br><strong>mean(cols)</strong> —— 计算每组中一列或多列的平均值<br><strong>min(cols)</strong> —— 计算每组中一列或多列的最小值<br><strong>sum(cols)</strong> —— 计算每组中一列或多列的总和</p><h2 id="apply-函数"><a class="markdownIt-Anchor" href="#apply-函数"></a> apply 函数</h2><p>将<code>df</code>的每一列应用函数f：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.foreach(f) 或者 df.rdd.foreach(f)</span><br></pre></td></tr></table></figure><p>将<code>df</code>的每一块应用函数f：</p><p>将df的每一块应用函数f：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.foreachPartition(f) 或者 df.rdd.foreachPartition(f)</span><br></pre></td></tr></table></figure><h2 id="map和reduce应用返回类型seqrdds"><a class="markdownIt-Anchor" href="#map和reduce应用返回类型seqrdds"></a> 【Map和Reduce应用】返回类型seqRDDs</h2><h3 id="map函数应用"><a class="markdownIt-Anchor" href="#map函数应用"></a> map函数应用</h3><p>可以参考：<a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/index.html">Spark Python API</a> 学习</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.select(<span class="string">&#x27;User_ID&#x27;</span>).rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x,<span class="number">1</span>)).take(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">[(Row(User_ID=1000001), 1),</span><br><span class="line"> (Row(User_ID=1000001), 1),</span><br><span class="line"> (Row(User_ID=1000001), 1),</span><br><span class="line"> (Row(User_ID=1000001), 1),</span><br><span class="line"> (Row(User_ID=1000002), 1)]</span><br></pre></td></tr></table></figure><p>其中map在spark2.0就移除了，所以只能由<code>rdd.</code>调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.select(<span class="string">&#x27;col&#x27;</span>).rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> l: <span class="number">1</span> <span class="keyword">if</span> l <span class="keyword">in</span> [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>] <span class="keyword">else</span> <span class="number">0</span> ).collect()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.collect()) </span><br><span class="line"><span class="built_in">print</span>(y.collect())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[1, 2, 3]</span><br><span class="line">[(1, 1), (2, 4), (3, 9)]</span><br></pre></td></tr></table></figure><p>还有一种方式<code>mapPartitions</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_map_to_pandas</span>(<span class="params">rdds</span>):</span><br><span class="line">    <span class="keyword">return</span> [pd.DataFrame(<span class="built_in">list</span>(rdds))]</span><br><span class="line"></span><br><span class="line">data.rdd.mapPartitions(_map_to_pandas).collect()</span><br></pre></td></tr></table></figure><p>返回的是<code>list</code>。</p><h3 id="udf-函数应用"><a class="markdownIt-Anchor" href="#udf-函数应用"></a> udf 函数应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure><p><strong>定义一个 udf 函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">today</span>(<span class="params">day</span>):</span><br><span class="line">    <span class="keyword">if</span> day==<span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> datetime.datetime.fromtimestamp(<span class="built_in">int</span>(time.time())).strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> day</span><br><span class="line"></span><br><span class="line"><span class="comment">#返回类型为字符串类型</span></span><br><span class="line">udfday = udf(today, StringType())</span><br></pre></td></tr></table></figure><p><strong>使用</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&#x27;day&#x27;</span>, udfday(df.day))</span><br></pre></td></tr></table></figure><p>有点类似<code>apply</code>,定义一个 <code>udf</code> 方法, 用来返回今天的日期<code>(yyyy-MM-dd)</code></p><h2 id="删除"><a class="markdownIt-Anchor" href="#删除"></a> 删除</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.drop(<span class="string">&#x27;age&#x27;</span>).collect()</span><br><span class="line">df.drop(df.age).collect()</span><br></pre></td></tr></table></figure><p><code>dropna</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.na.drop()  <span class="comment"># 扔掉任何列包含na的行</span></span><br><span class="line">df = df.dropna(subset=[<span class="string">&#x27;col_name1&#x27;</span>, <span class="string">&#x27;col_name2&#x27;</span>])  <span class="comment"># 扔掉col1或col2中任一一列包含na的行</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.dropna().count()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">166821</span><br></pre></td></tr></table></figure><p>填充<code>NA</code>包括<code>fillna</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.fillna(-<span class="number">1</span>).show(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|</span><br><span class="line">+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                -1|                -1|    8370|</span><br><span class="line">|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|</span><br><span class="line">+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+</span><br><span class="line">only showing top 2 rows</span><br></pre></td></tr></table></figure><h2 id="去重"><a class="markdownIt-Anchor" href="#去重"></a> 去重</h2><h3 id="distinct返回一个不包含重复记录的dataframe"><a class="markdownIt-Anchor" href="#distinct返回一个不包含重复记录的dataframe"></a> distinct：返回一个不包含重复记录的DataFrame</h3><p>返回当前<code>DataFrame</code>中不重复的Row记录。该方法和接下来的<code>dropDuplicates()</code>方法不传入指定字段时的结果相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcDF.distinct()</span><br></pre></td></tr></table></figure><h3 id="dropduplicates根据指定字段去重"><a class="markdownIt-Anchor" href="#dropduplicates根据指定字段去重"></a> dropDuplicates：根据指定字段去重</h3><p>根据指定字段去重。类似于<code>select distinct a, b</code>操作<br>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.select(<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Gender&#x27;</span>).dropDuplicates().show()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">+-----+------+</span><br><span class="line">|  Age|Gender|</span><br><span class="line">+-----+------+</span><br><span class="line">|51-55|     F|</span><br><span class="line">|51-55|     M|</span><br><span class="line">|26-35|     F|</span><br><span class="line">|26-35|     M|</span><br><span class="line">|36-45|     F|</span><br><span class="line">|36-45|     M|</span><br><span class="line">|46-50|     F|</span><br><span class="line">|46-50|     M|</span><br><span class="line">|  55+|     F|</span><br><span class="line">|  55+|     M|</span><br><span class="line">|18-25|     F|</span><br><span class="line">| 0-17|     F|</span><br><span class="line">|18-25|     M|</span><br><span class="line">| 0-17|     M|</span><br><span class="line">+-----+------+</span><br></pre></td></tr></table></figure><h3 id="去除两个表重复的内容"><a class="markdownIt-Anchor" href="#去除两个表重复的内容"></a> 去除两个表重复的内容</h3><p>场景是要，依据B表与A表共有的内容，需要去除这部分共有的。<br>使用的逻辑是合并两张表，然后把匹配到的删除即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LeftDeleteRight</span>(<span class="params">test_left,test_right,left_col = <span class="string">&#x27;user_pin&#x27;</span>,right_col = <span class="string">&#x27;user_pin&#x27;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;right data process ...&#x27;</span>)</span><br><span class="line">    columns_right = test_right.columns</span><br><span class="line">    test_right = test_right.withColumn(<span class="string">&#x27;user_pin_right&#x27;</span>, test_right[right_col])</span><br><span class="line">    test_right = test_right.withColumn(<span class="string">&#x27;notDelete&#x27;</span>,  functions.lit(<span class="number">0</span>))</span><br><span class="line">    <span class="comment"># 删除其余的</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> columns_right:</span><br><span class="line">        test_right = test_right.drop(col)</span><br><span class="line">    <span class="comment"># 合并</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;rbind left and right data ...&#x27;</span>)</span><br><span class="line">    test_left = test_left.join(test_right, test_left[left_col] == test_right[<span class="string">&#x27;user_pin_right&#x27;</span>], <span class="string">&quot;left&quot;</span>)</span><br><span class="line">    test_left = test_left.fillna(<span class="number">1</span>)</span><br><span class="line">    test_left = test_left.where(<span class="string">&#x27;notDelete =1&#x27;</span>)</span><br><span class="line">    <span class="comment"># 去掉多余的字段</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;user_pin_right&#x27;</span>,<span class="string">&#x27;notDelete&#x27;</span>]:</span><br><span class="line">        test_left = test_left.drop(col)</span><br><span class="line">    <span class="keyword">return</span> test_left</span><br><span class="line"></span><br><span class="line">test_left = LeftDeleteRight(test_b,test_a,left_col = <span class="string">&#x27;user_pin&#x27;</span>,right_col = <span class="string">&#x27;user_pin&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="格式转换"><a class="markdownIt-Anchor" href="#格式转换"></a> 格式转换</h1><p><code>Pandas</code>和<code>spark.dataframe</code>互转<br><code>Pandas</code>和<code>Spark</code>的<code>DataFrame</code>两者互相转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pandas_df = spark_df.toPandas() </span><br><span class="line">spark_df = sqlContext.createDataFrame(pandas_df)</span><br></pre></td></tr></table></figure><p>转化为pandas，但是该数据要读入内存，如果数据量大的话，很难跑得动</p><p>两者的异同：</p><p>Pyspark DataFrame是在分布式节点上运行一些数据操作，而pandas是不可能的；<br>Pyspark DataFrame的数据反映比较缓慢，没有Pandas那么及时反映；<br>Pyspark DataFrame的数据框是不可变的，不能任意添加列，只能通过合并进行；<br>pandas比Pyspark DataFrame有更多方便的操作以及很强大</p><p><strong>转化为RDD</strong><br>与Spark RDD的相互转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd_df = df.rdd </span><br><span class="line">df = rdd_df.toDF()</span><br></pre></td></tr></table></figure><h1 id="sql操作"><a class="markdownIt-Anchor" href="#sql操作"></a> SQL操作</h1><p><code>DataFrame</code>注册成<code>SQL</code>的表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.createOrReplaceTempView(<span class="string">&quot;TBL1&quot;</span>)</span><br></pre></td></tr></table></figure><p>进行<code>SQL</code>查询（返回<code>DataFrame</code>）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf()</span><br><span class="line">ss = SparkSession.builder.appName(<span class="string">&quot;APP_NAME&quot;</span>).config(conf=conf).getOrCreate()</span><br><span class="line"></span><br><span class="line">df = ss.sql(“SELECT name, age FROM TBL1 WHERE age &gt;= <span class="number">13</span> AND age &lt;= <span class="number">19</span>″)</span><br></pre></td></tr></table></figure><h1 id="读写csv"><a class="markdownIt-Anchor" href="#读写csv"></a> 读写csv</h1><p>在Python中，我们也可以使用<code>SQLContext</code>类中 <code>load/save</code>函数来读取和保存<code>CSV</code>文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext</span><br><span class="line">sqlContext = SQLContext(sc)  </span><br><span class="line">df = sqlContext.load(source=<span class="string">&quot;com.databricks.spark.csv&quot;</span>, header=<span class="string">&quot;true&quot;</span>, path = <span class="string">&quot;cars.csv&quot;</span>)</span><br><span class="line">df.select(<span class="string">&quot;year&quot;</span>, <span class="string">&quot;model&quot;</span>).save(<span class="string">&quot;newcars.csv&quot;</span>, <span class="string">&quot;com.databricks.spark.csv&quot;</span>,header=<span class="string">&quot;true&quot;</span>)</span><br></pre></td></tr></table></figure><p>其中，<code>header</code>代表是否显示表头。<br>其中主函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save(path=<span class="literal">None</span>, <span class="built_in">format</span>=<span class="literal">None</span>, mode=<span class="literal">None</span>, partitionBy=<span class="literal">None</span>, **options)[source]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Parameters:</span><br><span class="line"></span><br><span class="line">path – the path in a Hadoop supported file system</span><br><span class="line"></span><br><span class="line">format – the format used to save</span><br><span class="line"></span><br><span class="line">mode –</span><br><span class="line"></span><br><span class="line">specifies the behavior of the save operation when data already</span><br><span class="line">exists.</span><br><span class="line"></span><br><span class="line">append: Append contents of this DataFrame to existing data.</span><br><span class="line"></span><br><span class="line">overwrite: Overwrite existing data.</span><br><span class="line"></span><br><span class="line">ignore: Silently ignore this operation if data already exists.</span><br><span class="line"></span><br><span class="line">error (default case): Throw an exception if data already exists.</span><br><span class="line"></span><br><span class="line">partitionBy – names of partitioning columns</span><br><span class="line"></span><br><span class="line">options – all other string options</span><br></pre></td></tr></table></figure><p>📖<a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_26917383/article/details/80500349">参考</a></p><hr></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="mailto:undefined">sky_dream</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="https://blog.skysmile.ltd/skydream/994/">https://blog.skysmile.ltd/skydream/994/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.skysmile.ltd" target="_blank">sky_dream</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PySpark/">PySpark</a></div><div class="post_share"><div class="social-share" data-image="/skydream/994/%5Cpyspark01.jpg" data-sites="weibo,twitter,wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/skydream/2506/"><img class="prev-cover" src="/skydream/2506/%5Chive01.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hive去重方法简记</div></div></a></div><div class="next-post pull-right"><a href="/skydream/38e1/"><img class="next-cover" src="/skydream/38e1/%5Csafetynet04.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Android手机通过SafetyNet检查</div></div></a></div></nav><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar009.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">sky_dream</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/sky-smile"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://weibo.com/lonelijian" target="_blank" title="weibo"><i class="fab fa-weibo"></i></a><a class="social-icon" href="https://t.me/+UatCJaOivACGilxa" target="_blank" title="telegram"><i class="fab fa-telegram"></i></a><a class="social-icon" href="https://steamcommunity.com/id/sky_smile" target="_blank" title="steam"><i class="fab fa-steam"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">人间正道是沧桑！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9F%A5"><span class="toc-number">1.</span> <span class="toc-text">查</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%85%83%E7%B4%A0%E6%9F%A5%E8%AF%A2%E6%93%8D%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">行元素查询操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%97%E5%85%83%E7%B4%A0%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">列元素操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F"><span class="toc-number">1.3.</span> <span class="toc-text">排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%BD%E6%A0%B7"><span class="toc-number">1.4.</span> <span class="toc-text">抽样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%89%E6%9D%A1%E4%BB%B6%E7%AD%9B%E9%80%89when-between"><span class="toc-number">1.5.</span> <span class="toc-text">按条件筛选when &#x2F; between</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A2%9E-%E6%94%B9"><span class="toc-number">2.</span> <span class="toc-text">增、改</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B0%E5%BB%BA%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.</span> <span class="toc-text">新建数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B0%E5%A2%9E%E6%95%B0%E6%8D%AE%E5%88%97-withcolumn"><span class="toc-number">2.2.</span> <span class="toc-text">新增数据列 withColumn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%BB%A4%E6%95%B0%E6%8D%AE"><span class="toc-number">2.3.</span> <span class="toc-text">过滤数据</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%88%E5%B9%B6-join-union"><span class="toc-number">3.</span> <span class="toc-text">合并 join &#x2F; union</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%AA%E5%90%91%E6%8B%BC%E6%8E%A5"><span class="toc-number">3.1.</span> <span class="toc-text">横向拼接</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#join%E6%A0%B9%E6%8D%AE%E6%9D%A1%E4%BB%B6"><span class="toc-number">3.2.</span> <span class="toc-text">Join根据条件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B1%82%E5%B9%B6%E9%9B%86-%E4%BA%A4%E9%9B%86"><span class="toc-number">3.3.</span> <span class="toc-text">求并集、交集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E9%9B%86"><span class="toc-number">3.4.</span> <span class="toc-text">差集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E9%9B%86"><span class="toc-number">3.5.</span> <span class="toc-text">交集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E9%9B%86"><span class="toc-number">3.6.</span> <span class="toc-text">并集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#union"><span class="toc-number">3.6.1.</span> <span class="toc-text">union</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#unionall"><span class="toc-number">3.6.2.</span> <span class="toc-text">unionAll</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E9%9B%86-%E5%8E%BB%E9%87%8D"><span class="toc-number">3.7.</span> <span class="toc-text">并集 + 去重</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%89%B2%E8%A1%8C%E8%BD%AC%E5%88%97"><span class="toc-number">3.8.</span> <span class="toc-text">分割：行转列</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">统计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%91%E6%95%B0%E7%BB%9F%E8%AE%A1%E4%B8%8E%E7%AD%9B%E9%80%89"><span class="toc-number">4.1.</span> <span class="toc-text">频数统计与筛选</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%BB%84%E7%BB%9F%E8%AE%A1"><span class="toc-number">4.2.</span> <span class="toc-text">分组统计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#apply-%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.</span> <span class="toc-text">apply 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#map%E5%92%8Creduce%E5%BA%94%E7%94%A8%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8Bseqrdds"><span class="toc-number">4.4.</span> <span class="toc-text">【Map和Reduce应用】返回类型seqRDDs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#map%E5%87%BD%E6%95%B0%E5%BA%94%E7%94%A8"><span class="toc-number">4.4.1.</span> <span class="toc-text">map函数应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#udf-%E5%87%BD%E6%95%B0%E5%BA%94%E7%94%A8"><span class="toc-number">4.4.2.</span> <span class="toc-text">udf 函数应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4"><span class="toc-number">4.5.</span> <span class="toc-text">删除</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%BB%E9%87%8D"><span class="toc-number">4.6.</span> <span class="toc-text">去重</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#distinct%E8%BF%94%E5%9B%9E%E4%B8%80%E4%B8%AA%E4%B8%8D%E5%8C%85%E5%90%AB%E9%87%8D%E5%A4%8D%E8%AE%B0%E5%BD%95%E7%9A%84dataframe"><span class="toc-number">4.6.1.</span> <span class="toc-text">distinct：返回一个不包含重复记录的DataFrame</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dropduplicates%E6%A0%B9%E6%8D%AE%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E5%8E%BB%E9%87%8D"><span class="toc-number">4.6.2.</span> <span class="toc-text">dropDuplicates：根据指定字段去重</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%BB%E9%99%A4%E4%B8%A4%E4%B8%AA%E8%A1%A8%E9%87%8D%E5%A4%8D%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-number">4.6.3.</span> <span class="toc-text">去除两个表重复的内容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2"><span class="toc-number">5.</span> <span class="toc-text">格式转换</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sql%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">SQL操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BB%E5%86%99csv"><span class="toc-number">7.</span> <span class="toc-text">读写csv</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/skydream/ceb445ba/" title="Windows建立符号链接"><img src="/skydream/ceb445ba/%5CWindows.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Windows建立符号链接"></a><div class="content"><a class="title" href="/skydream/ceb445ba/" title="Windows建立符号链接">Windows建立符号链接</a><time datetime="2022-05-09T04:32:35.000Z" title="发表于 2022-05-09 12:32:35">2022-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/skydream/86996560/" title="Steam Xbox驱动安装"><img src="/skydream/86996560/%5Csteam-logo.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Steam Xbox驱动安装"></a><div class="content"><a class="title" href="/skydream/86996560/" title="Steam Xbox驱动安装">Steam Xbox驱动安装</a><time datetime="2022-05-09T04:03:38.000Z" title="发表于 2022-05-09 12:03:38">2022-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/skydream/932c8b59/" title="联想电脑的打开方式选择器被劫持的解决方案"><img src="/skydream/932c8b59/%5Clenovo.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="联想电脑的打开方式选择器被劫持的解决方案"></a><div class="content"><a class="title" href="/skydream/932c8b59/" title="联想电脑的打开方式选择器被劫持的解决方案">联想电脑的打开方式选择器被劫持的解决方案</a><time datetime="2022-05-09T03:36:30.000Z" title="发表于 2022-05-09 11:36:30">2022-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/skydream/71d7821a/" title="Windows程序包管理器Winget"><img src="/skydream/71d7821a/%5Cmaxresdefault.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Windows程序包管理器Winget"></a><div class="content"><a class="title" href="/skydream/71d7821a/" title="Windows程序包管理器Winget">Windows程序包管理器Winget</a><time datetime="2022-04-26T07:06:02.000Z" title="发表于 2022-04-26 15:06:02">2022-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/skydream/682307b7/" title="Windows下的包管理器Scoop"><img src="/skydream/682307b7/%5CSnipaste_2022-04-25_17-32-21.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Windows下的包管理器Scoop"></a><div class="content"><a class="title" href="/skydream/682307b7/" title="Windows下的包管理器Scoop">Windows下的包管理器Scoop</a><time datetime="2022-04-25T09:07:44.000Z" title="发表于 2022-04-25 17:07:44">2022-04-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022<i style="color:#ff6a6a" class="fas fa-heartbeat faa-tada animated"></i> sky_dream</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="https://blog.skysmile.ltd">I only wish to face the sea, with spring blossoms!</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine(){function n(){new Valine(Object.assign({el:"#vcomment",appId:"QXBEyX9wUHqWDn7ozniywjwQ-MdYXbMMI",appKey:"AVtyAeSg8tjutfmFTO3qth2g",avatar:"monsterid",serverURLs:"https://QXBEyX9w.api.lncldglobal.com",emojiMaps:"",path:window.location.pathname,visitor:!1},null))}"function"==typeof Valine?n():getScript("https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js").then(n)}{function loadOtherComment(){loadValine()}btf.loadComment(document.getElementById("vcomment"),loadValine)}</script></div><script src="/js/sun_moon.js" async></script><link rel="stylesheet" href="/css/mycss.css" media="defer" onload='this.media="all"'><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script></div></body></html>